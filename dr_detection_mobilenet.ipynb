{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mild': 2443, 'Moderate': 5292, 'No DR': 25810, 'Proliferative DR': 708, 'Severe': 873}\n"
     ]
    }
   ],
   "source": [
    "# Define dataset path and classes\n",
    "dataset_path = './dataset'\n",
    "classes = ['Mild', 'Moderate', 'No DR', 'Proliferative DR', 'Severe']\n",
    "\n",
    "# Function to count images in each class\n",
    "def count_images_in_class(class_path):\n",
    "    return len(os.listdir(class_path))\n",
    "\n",
    "# Count images in each class\n",
    "image_counts = {class_name: count_images_in_class(os.path.join(dataset_path, class_name)) for class_name in classes}\n",
    "print(image_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation and Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mild already has 2443 images, no augmentation needed\n",
      "Moderate already has 5292 images, no augmentation needed\n",
      "No DR already has 25810 images, no augmentation needed\n",
      "Augmenting Proliferative DR from 708 to 2000 images\n",
      "Augmenting Severe from 873 to 2000 images\n"
     ]
    }
   ],
   "source": [
    "# Define data augmentation strategy\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to augment and balance classes\n",
    "def balance_classes(dataset_path, classes, target_count=2000):\n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        image_count = count_images_in_class(class_path)\n",
    "        if image_count < target_count:\n",
    "            # Perform augmentation\n",
    "            datagen = ImageDataGenerator(\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                shear_range=10,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "            # Implement augmentation logic here\n",
    "            print(f'Augmenting {class_name} from {image_count} to {target_count} images')\n",
    "        else:\n",
    "            print(f'{class_name} already has {image_count} images, no augmentation needed')\n",
    "\n",
    "balance_classes(dataset_path, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28103 images belonging to 5 classes.\n",
      "Found 7023 images belonging to 5 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\navee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m878/878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1163s\u001b[0m 1s/step - accuracy: 0.7201 - loss: 0.9042 - val_accuracy: 0.7410 - val_loss: 0.7803 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m  1/878\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:45\u001b[0m 599ms/step - accuracy: 0.8438 - loss: 0.6446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\navee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m878/878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - accuracy: 0.8438 - loss: 0.6446 - val_accuracy: 0.6667 - val_loss: 0.8926 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m878/878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m688s\u001b[0m 781ms/step - accuracy: 0.7456 - loss: 0.7558 - val_accuracy: 0.7440 - val_loss: 0.7699 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m878/878\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - accuracy: 0.7812 - loss: 0.6072 - val_accuracy: 0.6667 - val_loss: 0.7678 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m189/878\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:46\u001b[0m 590ms/step - accuracy: 0.7255 - loss: 0.7851"
     ]
    }
   ],
   "source": [
    "# Define preprocessing and training steps\n",
    "def train_mobilenet_model(dataset_path, classes, target_size=(224, 224), batch_size=32):\n",
    "    # Data generators for training and validation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    # Load MobileNetV2 model\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(len(classes), activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freeze base layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size,\n",
    "        epochs=10,\n",
    "        callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001),\n",
    "                   EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "    return model, history, train_generator, validation_generator\n",
    "\n",
    "model, history, train_generator, validation_generator = train_mobilenet_model(dataset_path, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(model, validation_generator, classes):\n",
    "    loss, accuracy = model.evaluate(validation_generator)\n",
    "    print(f'Test accuracy: {accuracy:.2f}')\n",
    "\n",
    "    # Generate predictions\n",
    "    predictions = model.predict(validation_generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = validation_generator.classes\n",
    "\n",
    "    # Print classification report and confusion matrix\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=classes))\n",
    "    conf_mat = confusion_matrix(true_classes, predicted_classes)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "evaluate_model(model, validation_generator, classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
